{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e9238ce-00fc-44ba-851c-c94904394b68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e9238ce-00fc-44ba-851c-c94904394b68",
    "outputId": "3b4e5888-be28-41e2-acc6-8cf5eabbfe72"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import random\n",
    "from skimage.io import imread\n",
    "from PIL import Image\n",
    "\n",
    "# Tensorflow and Keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "  # Image processing\n",
    "from keras.utils import img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.layers import Rescaling, RandomFlip, RandomTranslation, RandomRotation, RandomContrast\n",
    "  # Model\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, GlobalAveragePooling2D\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88017c1e-0fe0-4746-aaa2-7d6d6ef85608",
   "metadata": {
    "id": "88017c1e-0fe0-4746-aaa2-7d6d6ef85608"
   },
   "outputs": [],
   "source": [
    "train_dir = Path('images_split/Training')\n",
    "val_dir = Path('images_split/Validation')\n",
    "test_dir = Path('images_split/Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf389046-85bc-4280-b6cf-850dc050dd77",
   "metadata": {
    "id": "bf389046-85bc-4280-b6cf-850dc050dd77"
   },
   "source": [
    "### Image Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a150117-61ec-4208-9b5e-c7413c74fe8a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a150117-61ec-4208-9b5e-c7413c74fe8a",
    "outputId": "8bff705b-37f6-4e0f-f444-ad816728db09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11596 files belonging to 114 classes.\n",
      "Found 2485 files belonging to 114 classes.\n",
      "Found 2486 files belonging to 114 classes.\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 256, 256\n",
    "batch_size = 64\n",
    "\n",
    "train_generator = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical')\n",
    "\n",
    "val_generator = image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    image_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c676be-9c70-4c97-a38f-7d1a706d769b",
   "metadata": {
    "id": "a8c676be-9c70-4c97-a38f-7d1a706d769b"
   },
   "source": [
    "# Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1am06b16wBLM",
   "metadata": {
    "id": "1am06b16wBLM"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization\n",
    "\n",
    "def create_model(input_shape, n_classes, optimizer='adam', metrics=['accuracy']):\n",
    "    \"\"\"\n",
    "    Compiles a model integrated with IceptionV3 pretrained layers and data augmentation\n",
    "        input_shape: tuple - the shape of input images (width, height, channels)\n",
    "        n_classes: int - number of classes for the output layer\n",
    "        optimizer: string (defaults to 'adam')\n",
    "        optimizer: list (defaults to 'accuracy')\n",
    "    \"\"\"\n",
    "    # Data augmentation layers\n",
    "    data_augmentation = Sequential([\n",
    "        Rescaling(1./255),\n",
    "        RandomFlip(\"horizontal_and_vertical\"),\n",
    "        RandomContrast(0.3),\n",
    "        RandomTranslation(0.1, 0.2),\n",
    "        RandomRotation(0.2)\n",
    "    ])\n",
    "\n",
    "    # Input + data augmentation\n",
    "    input_img = Input(shape=input_shape)\n",
    "    augmented_img = data_augmentation(input_img)\n",
    "\n",
    "    # Load the InceptionV3 model with pre-trained weights, excluding the top (fully connected) layers\n",
    "    inception_base = InceptionV3(include_top=False, weights='imagenet', input_tensor=augmented_img)\n",
    "    inception_base.trainable = False\n",
    "\n",
    "    # Adding last layers\n",
    "    pooled_output = GlobalAveragePooling2D()(inception_base.output)\n",
    "    dense_layer = Dense(512, activation='relu')(pooled_output)\n",
    "    batch_norm_layer = BatchNormalization()(dense_layer)\n",
    "    dropout_layer = Dropout(0.3)(batch_norm_layer)  # reduced dropout\n",
    "    dense_layer = Dense(128, activation='relu')(dropout_layer)\n",
    "    batch_norm_layer = BatchNormalization()(dense_layer)\n",
    "    dropout_layer = Dropout(0.3)(batch_norm_layer)  # consistent dropout\n",
    "    output_layer = Dense(n_classes, activation='softmax')(dropout_layer)\n",
    "\n",
    "    # Final model\n",
    "    model = Model(inputs=input_img, outputs=output_layer)\n",
    "\n",
    "    # Compile\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "CBpppLxcwBN0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CBpppLxcwBN0",
    "outputId": "be36c597-7875-4ba4-a432-d4ad64cb5c85"
   },
   "outputs": [],
   "source": [
    "opt_adam = Adam(learning_rate=0.001)\n",
    "f1 = F1Score(num_classes=114, average='weighted')\n",
    "\n",
    "model = create_model(input_shape=(256, 256, 3),\n",
    "                     n_classes=114,\n",
    "                     optimizer=opt_adam,\n",
    "                     metrics=['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9KtTGx0iwBQP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9KtTGx0iwBQP",
    "outputId": "80c1bef6-4b96-4cb8-a1cd-d80b7722a025"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 256, 256, 3)  0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, 127, 127, 32  864         ['sequential_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_96 (BatchN  (None, 127, 127, 32  96         ['conv2d_94[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_94 (Activation)     (None, 127, 127, 32  0           ['batch_normalization_96[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, 125, 125, 32  9216        ['activation_94[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_97 (BatchN  (None, 125, 125, 32  96         ['conv2d_95[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_95 (Activation)     (None, 125, 125, 32  0           ['batch_normalization_97[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)             (None, 125, 125, 64  18432       ['activation_95[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_98 (BatchN  (None, 125, 125, 64  192        ['conv2d_96[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_96 (Activation)     (None, 125, 125, 64  0           ['batch_normalization_98[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 62, 62, 64)  0           ['activation_96[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)             (None, 62, 62, 80)   5120        ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_99 (BatchN  (None, 62, 62, 80)  240         ['conv2d_97[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_97 (Activation)     (None, 62, 62, 80)   0           ['batch_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)             (None, 60, 60, 192)  138240      ['activation_97[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_100 (Batch  (None, 60, 60, 192)  576        ['conv2d_98[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_98 (Activation)     (None, 60, 60, 192)  0           ['batch_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 29, 29, 192)  0          ['activation_98[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)            (None, 29, 29, 64)   12288       ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_104 (Batch  (None, 29, 29, 64)  192         ['conv2d_102[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_102 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_104[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)            (None, 29, 29, 48)   9216        ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)            (None, 29, 29, 96)   55296       ['activation_102[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_102 (Batch  (None, 29, 29, 48)  144         ['conv2d_100[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_105 (Batch  (None, 29, 29, 96)  288         ['conv2d_103[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_100 (Activation)    (None, 29, 29, 48)   0           ['batch_normalization_102[0][0]']\n",
      "                                                                                                  \n",
      " activation_103 (Activation)    (None, 29, 29, 96)   0           ['batch_normalization_105[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_9 (AveragePo  (None, 29, 29, 192)  0          ['max_pooling2d_5[0][0]']        \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)             (None, 29, 29, 64)   12288       ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)            (None, 29, 29, 64)   76800       ['activation_100[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)            (None, 29, 29, 96)   82944       ['activation_103[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)            (None, 29, 29, 32)   6144        ['average_pooling2d_9[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_101 (Batch  (None, 29, 29, 64)  192         ['conv2d_99[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_103 (Batch  (None, 29, 29, 64)  192         ['conv2d_101[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_106 (Batch  (None, 29, 29, 96)  288         ['conv2d_104[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_107 (Batch  (None, 29, 29, 32)  96          ['conv2d_105[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_99 (Activation)     (None, 29, 29, 64)   0           ['batch_normalization_101[0][0]']\n",
      "                                                                                                  \n",
      " activation_101 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_103[0][0]']\n",
      "                                                                                                  \n",
      " activation_104 (Activation)    (None, 29, 29, 96)   0           ['batch_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " activation_105 (Activation)    (None, 29, 29, 32)   0           ['batch_normalization_107[0][0]']\n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 29, 29, 256)  0           ['activation_99[0][0]',          \n",
      "                                                                  'activation_101[0][0]',         \n",
      "                                                                  'activation_104[0][0]',         \n",
      "                                                                  'activation_105[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)            (None, 29, 29, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_111 (Batch  (None, 29, 29, 64)  192         ['conv2d_109[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_109 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_111[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)            (None, 29, 29, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)            (None, 29, 29, 96)   55296       ['activation_109[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_109 (Batch  (None, 29, 29, 48)  144         ['conv2d_107[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_112 (Batch  (None, 29, 29, 96)  288         ['conv2d_110[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_107 (Activation)    (None, 29, 29, 48)   0           ['batch_normalization_109[0][0]']\n",
      "                                                                                                  \n",
      " activation_110 (Activation)    (None, 29, 29, 96)   0           ['batch_normalization_112[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_10 (AverageP  (None, 29, 29, 256)  0          ['mixed0[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)            (None, 29, 29, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)            (None, 29, 29, 64)   76800       ['activation_107[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)            (None, 29, 29, 96)   82944       ['activation_110[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)            (None, 29, 29, 64)   16384       ['average_pooling2d_10[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_108 (Batch  (None, 29, 29, 64)  192         ['conv2d_106[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_110 (Batch  (None, 29, 29, 64)  192         ['conv2d_108[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_113 (Batch  (None, 29, 29, 96)  288         ['conv2d_111[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_114 (Batch  (None, 29, 29, 64)  192         ['conv2d_112[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_106 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_108[0][0]']\n",
      "                                                                                                  \n",
      " activation_108 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_110[0][0]']\n",
      "                                                                                                  \n",
      " activation_111 (Activation)    (None, 29, 29, 96)   0           ['batch_normalization_113[0][0]']\n",
      "                                                                                                  \n",
      " activation_112 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_114[0][0]']\n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 29, 29, 288)  0           ['activation_106[0][0]',         \n",
      "                                                                  'activation_108[0][0]',         \n",
      "                                                                  'activation_111[0][0]',         \n",
      "                                                                  'activation_112[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)            (None, 29, 29, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_118 (Batch  (None, 29, 29, 64)  192         ['conv2d_116[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_116 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_118[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)            (None, 29, 29, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)            (None, 29, 29, 96)   55296       ['activation_116[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_116 (Batch  (None, 29, 29, 48)  144         ['conv2d_114[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_119 (Batch  (None, 29, 29, 96)  288         ['conv2d_117[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_114 (Activation)    (None, 29, 29, 48)   0           ['batch_normalization_116[0][0]']\n",
      "                                                                                                  \n",
      " activation_117 (Activation)    (None, 29, 29, 96)   0           ['batch_normalization_119[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_11 (AverageP  (None, 29, 29, 288)  0          ['mixed1[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)            (None, 29, 29, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)            (None, 29, 29, 64)   76800       ['activation_114[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)            (None, 29, 29, 96)   82944       ['activation_117[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)            (None, 29, 29, 64)   18432       ['average_pooling2d_11[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_115 (Batch  (None, 29, 29, 64)  192         ['conv2d_113[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_117 (Batch  (None, 29, 29, 64)  192         ['conv2d_115[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_120 (Batch  (None, 29, 29, 96)  288         ['conv2d_118[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_121 (Batch  (None, 29, 29, 64)  192         ['conv2d_119[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_113 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_115[0][0]']\n",
      "                                                                                                  \n",
      " activation_115 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_117[0][0]']\n",
      "                                                                                                  \n",
      " activation_118 (Activation)    (None, 29, 29, 96)   0           ['batch_normalization_120[0][0]']\n",
      "                                                                                                  \n",
      " activation_119 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_121[0][0]']\n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 29, 29, 288)  0           ['activation_113[0][0]',         \n",
      "                                                                  'activation_115[0][0]',         \n",
      "                                                                  'activation_118[0][0]',         \n",
      "                                                                  'activation_119[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)            (None, 29, 29, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_123 (Batch  (None, 29, 29, 64)  192         ['conv2d_121[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_121 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_123[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)            (None, 29, 29, 96)   55296       ['activation_121[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_124 (Batch  (None, 29, 29, 96)  288         ['conv2d_122[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_122 (Activation)    (None, 29, 29, 96)   0           ['batch_normalization_124[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)            (None, 14, 14, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)            (None, 14, 14, 96)   82944       ['activation_122[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_122 (Batch  (None, 14, 14, 384)  1152       ['conv2d_120[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_125 (Batch  (None, 14, 14, 96)  288         ['conv2d_123[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_120 (Activation)    (None, 14, 14, 384)  0           ['batch_normalization_122[0][0]']\n",
      "                                                                                                  \n",
      " activation_123 (Activation)    (None, 14, 14, 96)   0           ['batch_normalization_125[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 14, 14, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 14, 14, 768)  0           ['activation_120[0][0]',         \n",
      "                                                                  'activation_123[0][0]',         \n",
      "                                                                  'max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)            (None, 14, 14, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_130 (Batch  (None, 14, 14, 128)  384        ['conv2d_128[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_128 (Activation)    (None, 14, 14, 128)  0           ['batch_normalization_130[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)            (None, 14, 14, 128)  114688      ['activation_128[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_131 (Batch  (None, 14, 14, 128)  384        ['conv2d_129[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_129 (Activation)    (None, 14, 14, 128)  0           ['batch_normalization_131[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)            (None, 14, 14, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)            (None, 14, 14, 128)  114688      ['activation_129[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_127 (Batch  (None, 14, 14, 128)  384        ['conv2d_125[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_132 (Batch  (None, 14, 14, 128)  384        ['conv2d_130[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_125 (Activation)    (None, 14, 14, 128)  0           ['batch_normalization_127[0][0]']\n",
      "                                                                                                  \n",
      " activation_130 (Activation)    (None, 14, 14, 128)  0           ['batch_normalization_132[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)            (None, 14, 14, 128)  114688      ['activation_125[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)            (None, 14, 14, 128)  114688      ['activation_130[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_128 (Batch  (None, 14, 14, 128)  384        ['conv2d_126[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_133 (Batch  (None, 14, 14, 128)  384        ['conv2d_131[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_126 (Activation)    (None, 14, 14, 128)  0           ['batch_normalization_128[0][0]']\n",
      "                                                                                                  \n",
      " activation_131 (Activation)    (None, 14, 14, 128)  0           ['batch_normalization_133[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_12 (AverageP  (None, 14, 14, 768)  0          ['mixed3[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)            (None, 14, 14, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)            (None, 14, 14, 192)  172032      ['activation_126[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)            (None, 14, 14, 192)  172032      ['activation_131[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)            (None, 14, 14, 192)  147456      ['average_pooling2d_12[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_126 (Batch  (None, 14, 14, 192)  576        ['conv2d_124[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_129 (Batch  (None, 14, 14, 192)  576        ['conv2d_127[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_134 (Batch  (None, 14, 14, 192)  576        ['conv2d_132[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_135 (Batch  (None, 14, 14, 192)  576        ['conv2d_133[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_124 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_126[0][0]']\n",
      "                                                                                                  \n",
      " activation_127 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_129[0][0]']\n",
      "                                                                                                  \n",
      " activation_132 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_134[0][0]']\n",
      "                                                                                                  \n",
      " activation_133 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_135[0][0]']\n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 14, 14, 768)  0           ['activation_124[0][0]',         \n",
      "                                                                  'activation_127[0][0]',         \n",
      "                                                                  'activation_132[0][0]',         \n",
      "                                                                  'activation_133[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_138 (Conv2D)            (None, 14, 14, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_140 (Batch  (None, 14, 14, 160)  480        ['conv2d_138[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_138 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_140[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)            (None, 14, 14, 160)  179200      ['activation_138[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_141 (Batch  (None, 14, 14, 160)  480        ['conv2d_139[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_139 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_141[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_135 (Conv2D)            (None, 14, 14, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)            (None, 14, 14, 160)  179200      ['activation_139[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_137 (Batch  (None, 14, 14, 160)  480        ['conv2d_135[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_142 (Batch  (None, 14, 14, 160)  480        ['conv2d_140[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_135 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_137[0][0]']\n",
      "                                                                                                  \n",
      " activation_140 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_142[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_136 (Conv2D)            (None, 14, 14, 160)  179200      ['activation_135[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)            (None, 14, 14, 160)  179200      ['activation_140[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_138 (Batch  (None, 14, 14, 160)  480        ['conv2d_136[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_143 (Batch  (None, 14, 14, 160)  480        ['conv2d_141[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_136 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_138[0][0]']\n",
      "                                                                                                  \n",
      " activation_141 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_143[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_13 (AverageP  (None, 14, 14, 768)  0          ['mixed4[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_134 (Conv2D)            (None, 14, 14, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_137 (Conv2D)            (None, 14, 14, 192)  215040      ['activation_136[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)            (None, 14, 14, 192)  215040      ['activation_141[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)            (None, 14, 14, 192)  147456      ['average_pooling2d_13[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_136 (Batch  (None, 14, 14, 192)  576        ['conv2d_134[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_139 (Batch  (None, 14, 14, 192)  576        ['conv2d_137[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_144 (Batch  (None, 14, 14, 192)  576        ['conv2d_142[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_145 (Batch  (None, 14, 14, 192)  576        ['conv2d_143[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_134 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_136[0][0]']\n",
      "                                                                                                  \n",
      " activation_137 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_139[0][0]']\n",
      "                                                                                                  \n",
      " activation_142 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_144[0][0]']\n",
      "                                                                                                  \n",
      " activation_143 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_145[0][0]']\n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 14, 14, 768)  0           ['activation_134[0][0]',         \n",
      "                                                                  'activation_137[0][0]',         \n",
      "                                                                  'activation_142[0][0]',         \n",
      "                                                                  'activation_143[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)            (None, 14, 14, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_150 (Batch  (None, 14, 14, 160)  480        ['conv2d_148[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_148 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_150[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)            (None, 14, 14, 160)  179200      ['activation_148[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_151 (Batch  (None, 14, 14, 160)  480        ['conv2d_149[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_149 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_151[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)            (None, 14, 14, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_150 (Conv2D)            (None, 14, 14, 160)  179200      ['activation_149[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_147 (Batch  (None, 14, 14, 160)  480        ['conv2d_145[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_152 (Batch  (None, 14, 14, 160)  480        ['conv2d_150[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_145 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_147[0][0]']\n",
      "                                                                                                  \n",
      " activation_150 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_152[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)            (None, 14, 14, 160)  179200      ['activation_145[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_151 (Conv2D)            (None, 14, 14, 160)  179200      ['activation_150[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_148 (Batch  (None, 14, 14, 160)  480        ['conv2d_146[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_153 (Batch  (None, 14, 14, 160)  480        ['conv2d_151[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_146 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_148[0][0]']\n",
      "                                                                                                  \n",
      " activation_151 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_153[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_14 (AverageP  (None, 14, 14, 768)  0          ['mixed5[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)            (None, 14, 14, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)            (None, 14, 14, 192)  215040      ['activation_146[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_152 (Conv2D)            (None, 14, 14, 192)  215040      ['activation_151[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_153 (Conv2D)            (None, 14, 14, 192)  147456      ['average_pooling2d_14[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_146 (Batch  (None, 14, 14, 192)  576        ['conv2d_144[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_149 (Batch  (None, 14, 14, 192)  576        ['conv2d_147[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_154 (Batch  (None, 14, 14, 192)  576        ['conv2d_152[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_155 (Batch  (None, 14, 14, 192)  576        ['conv2d_153[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_144 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_146[0][0]']\n",
      "                                                                                                  \n",
      " activation_147 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_149[0][0]']\n",
      "                                                                                                  \n",
      " activation_152 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_154[0][0]']\n",
      "                                                                                                  \n",
      " activation_153 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_155[0][0]']\n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 14, 14, 768)  0           ['activation_144[0][0]',         \n",
      "                                                                  'activation_147[0][0]',         \n",
      "                                                                  'activation_152[0][0]',         \n",
      "                                                                  'activation_153[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_158 (Conv2D)            (None, 14, 14, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_160 (Batch  (None, 14, 14, 192)  576        ['conv2d_158[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_158 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_160[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_159 (Conv2D)            (None, 14, 14, 192)  258048      ['activation_158[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_161 (Batch  (None, 14, 14, 192)  576        ['conv2d_159[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_159 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_161[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_155 (Conv2D)            (None, 14, 14, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_160 (Conv2D)            (None, 14, 14, 192)  258048      ['activation_159[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_157 (Batch  (None, 14, 14, 192)  576        ['conv2d_155[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_162 (Batch  (None, 14, 14, 192)  576        ['conv2d_160[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_155 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_157[0][0]']\n",
      "                                                                                                  \n",
      " activation_160 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_162[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_156 (Conv2D)            (None, 14, 14, 192)  258048      ['activation_155[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_161 (Conv2D)            (None, 14, 14, 192)  258048      ['activation_160[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_158 (Batch  (None, 14, 14, 192)  576        ['conv2d_156[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_163 (Batch  (None, 14, 14, 192)  576        ['conv2d_161[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_156 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_158[0][0]']\n",
      "                                                                                                  \n",
      " activation_161 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_163[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_15 (AverageP  (None, 14, 14, 768)  0          ['mixed6[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_154 (Conv2D)            (None, 14, 14, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_157 (Conv2D)            (None, 14, 14, 192)  258048      ['activation_156[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_162 (Conv2D)            (None, 14, 14, 192)  258048      ['activation_161[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_163 (Conv2D)            (None, 14, 14, 192)  147456      ['average_pooling2d_15[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_156 (Batch  (None, 14, 14, 192)  576        ['conv2d_154[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_159 (Batch  (None, 14, 14, 192)  576        ['conv2d_157[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_164 (Batch  (None, 14, 14, 192)  576        ['conv2d_162[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_165 (Batch  (None, 14, 14, 192)  576        ['conv2d_163[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_154 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_156[0][0]']\n",
      "                                                                                                  \n",
      " activation_157 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_159[0][0]']\n",
      "                                                                                                  \n",
      " activation_162 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_164[0][0]']\n",
      "                                                                                                  \n",
      " activation_163 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_165[0][0]']\n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 14, 14, 768)  0           ['activation_154[0][0]',         \n",
      "                                                                  'activation_157[0][0]',         \n",
      "                                                                  'activation_162[0][0]',         \n",
      "                                                                  'activation_163[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_166 (Conv2D)            (None, 14, 14, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_168 (Batch  (None, 14, 14, 192)  576        ['conv2d_166[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_166 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_168[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_167 (Conv2D)            (None, 14, 14, 192)  258048      ['activation_166[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_169 (Batch  (None, 14, 14, 192)  576        ['conv2d_167[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_167 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_169[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_164 (Conv2D)            (None, 14, 14, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_168 (Conv2D)            (None, 14, 14, 192)  258048      ['activation_167[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_166 (Batch  (None, 14, 14, 192)  576        ['conv2d_164[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_170 (Batch  (None, 14, 14, 192)  576        ['conv2d_168[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_164 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_166[0][0]']\n",
      "                                                                                                  \n",
      " activation_168 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_170[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_165 (Conv2D)            (None, 6, 6, 320)    552960      ['activation_164[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_169 (Conv2D)            (None, 6, 6, 192)    331776      ['activation_168[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_167 (Batch  (None, 6, 6, 320)   960         ['conv2d_165[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_171 (Batch  (None, 6, 6, 192)   576         ['conv2d_169[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_165 (Activation)    (None, 6, 6, 320)    0           ['batch_normalization_167[0][0]']\n",
      "                                                                                                  \n",
      " activation_169 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_171[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 6, 6, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 6, 6, 1280)   0           ['activation_165[0][0]',         \n",
      "                                                                  'activation_169[0][0]',         \n",
      "                                                                  'max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_174 (Conv2D)            (None, 6, 6, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_176 (Batch  (None, 6, 6, 448)   1344        ['conv2d_174[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_174 (Activation)    (None, 6, 6, 448)    0           ['batch_normalization_176[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_171 (Conv2D)            (None, 6, 6, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_175 (Conv2D)            (None, 6, 6, 384)    1548288     ['activation_174[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_173 (Batch  (None, 6, 6, 384)   1152        ['conv2d_171[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_177 (Batch  (None, 6, 6, 384)   1152        ['conv2d_175[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_171 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_173[0][0]']\n",
      "                                                                                                  \n",
      " activation_175 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_177[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_172 (Conv2D)            (None, 6, 6, 384)    442368      ['activation_171[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_173 (Conv2D)            (None, 6, 6, 384)    442368      ['activation_171[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_176 (Conv2D)            (None, 6, 6, 384)    442368      ['activation_175[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_177 (Conv2D)            (None, 6, 6, 384)    442368      ['activation_175[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_16 (AverageP  (None, 6, 6, 1280)  0           ['mixed8[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_170 (Conv2D)            (None, 6, 6, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_174 (Batch  (None, 6, 6, 384)   1152        ['conv2d_172[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_175 (Batch  (None, 6, 6, 384)   1152        ['conv2d_173[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_178 (Batch  (None, 6, 6, 384)   1152        ['conv2d_176[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_179 (Batch  (None, 6, 6, 384)   1152        ['conv2d_177[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_178 (Conv2D)            (None, 6, 6, 192)    245760      ['average_pooling2d_16[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_172 (Batch  (None, 6, 6, 320)   960         ['conv2d_170[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_172 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_174[0][0]']\n",
      "                                                                                                  \n",
      " activation_173 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_175[0][0]']\n",
      "                                                                                                  \n",
      " activation_176 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_178[0][0]']\n",
      "                                                                                                  \n",
      " activation_177 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_179[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_180 (Batch  (None, 6, 6, 192)   576         ['conv2d_178[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_170 (Activation)    (None, 6, 6, 320)    0           ['batch_normalization_172[0][0]']\n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 6, 6, 768)    0           ['activation_172[0][0]',         \n",
      "                                                                  'activation_173[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 6, 6, 768)    0           ['activation_176[0][0]',         \n",
      "                                                                  'activation_177[0][0]']         \n",
      "                                                                                                  \n",
      " activation_178 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_180[0][0]']\n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 6, 6, 2048)   0           ['activation_170[0][0]',         \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate_2[0][0]',          \n",
      "                                                                  'activation_178[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_183 (Conv2D)            (None, 6, 6, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_185 (Batch  (None, 6, 6, 448)   1344        ['conv2d_183[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_183 (Activation)    (None, 6, 6, 448)    0           ['batch_normalization_185[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_180 (Conv2D)            (None, 6, 6, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_184 (Conv2D)            (None, 6, 6, 384)    1548288     ['activation_183[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_182 (Batch  (None, 6, 6, 384)   1152        ['conv2d_180[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_186 (Batch  (None, 6, 6, 384)   1152        ['conv2d_184[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_180 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_182[0][0]']\n",
      "                                                                                                  \n",
      " activation_184 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_186[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_181 (Conv2D)            (None, 6, 6, 384)    442368      ['activation_180[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_182 (Conv2D)            (None, 6, 6, 384)    442368      ['activation_180[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_185 (Conv2D)            (None, 6, 6, 384)    442368      ['activation_184[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_186 (Conv2D)            (None, 6, 6, 384)    442368      ['activation_184[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_17 (AverageP  (None, 6, 6, 2048)  0           ['mixed9[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_179 (Conv2D)            (None, 6, 6, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_183 (Batch  (None, 6, 6, 384)   1152        ['conv2d_181[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_184 (Batch  (None, 6, 6, 384)   1152        ['conv2d_182[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_187 (Batch  (None, 6, 6, 384)   1152        ['conv2d_185[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_188 (Batch  (None, 6, 6, 384)   1152        ['conv2d_186[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_187 (Conv2D)            (None, 6, 6, 192)    393216      ['average_pooling2d_17[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_181 (Batch  (None, 6, 6, 320)   960         ['conv2d_179[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_181 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_183[0][0]']\n",
      "                                                                                                  \n",
      " activation_182 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_184[0][0]']\n",
      "                                                                                                  \n",
      " activation_185 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_187[0][0]']\n",
      "                                                                                                  \n",
      " activation_186 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_188[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_189 (Batch  (None, 6, 6, 192)   576         ['conv2d_187[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_179 (Activation)    (None, 6, 6, 320)    0           ['batch_normalization_181[0][0]']\n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 6, 6, 768)    0           ['activation_181[0][0]',         \n",
      "                                                                  'activation_182[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 6, 6, 768)    0           ['activation_185[0][0]',         \n",
      "                                                                  'activation_186[0][0]']         \n",
      "                                                                                                  \n",
      " activation_187 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_189[0][0]']\n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 6, 6, 2048)   0           ['activation_179[0][0]',         \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_3[0][0]',          \n",
      "                                                                  'activation_187[0][0]']         \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 512)          1049088     ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " batch_normalization_190 (Batch  (None, 512)         2048        ['dense_3[0][0]']                \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 512)          0           ['batch_normalization_190[0][0]']\n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          65664       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_191 (Batch  (None, 128)         512         ['dense_4[0][0]']                \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128)          0           ['batch_normalization_191[0][0]']\n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 114)          14706       ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 22,934,802\n",
      "Trainable params: 1,130,738\n",
      "Non-trainable params: 21,804,064\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tdDyjFOgwBVd",
   "metadata": {
    "id": "tdDyjFOgwBVd"
   },
   "outputs": [],
   "source": [
    "# Callbaks\n",
    "checkpoint = ModelCheckpoint(filepath='inceptionv3_model_best.weights.hdf5',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1,\n",
    "                             monitor='val_loss',\n",
    "                             mode='min')\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=10,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "hm55fTVax7NI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hm55fTVax7NI",
    "outputId": "ef0bcf71-09f4-4f2e-9942-1b113031e818"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "182/182 [==============================] - ETA: 0s - loss: 4.5171 - accuracy: 0.0800 - f1_score: 0.0684\n",
      "Epoch 1: val_loss improved from inf to 4.08030, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 63s 255ms/step - loss: 4.5171 - accuracy: 0.0800 - f1_score: 0.0684 - val_loss: 4.0803 - val_accuracy: 0.1227 - val_f1_score: 0.0890\n",
      "Epoch 2/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.9662 - accuracy: 0.1331 - f1_score: 0.1080\n",
      "Epoch 2: val_loss improved from 4.08030 to 3.77983, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 39s 213ms/step - loss: 3.9662 - accuracy: 0.1331 - f1_score: 0.1080 - val_loss: 3.7798 - val_accuracy: 0.1577 - val_f1_score: 0.1159\n",
      "Epoch 3/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.7178 - accuracy: 0.1633 - f1_score: 0.1375\n",
      "Epoch 3: val_loss improved from 3.77983 to 3.65620, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 40s 218ms/step - loss: 3.7182 - accuracy: 0.1632 - f1_score: 0.1374 - val_loss: 3.6562 - val_accuracy: 0.1771 - val_f1_score: 0.1397\n",
      "Epoch 4/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.6079 - accuracy: 0.1749 - f1_score: 0.1494\n",
      "Epoch 4: val_loss improved from 3.65620 to 3.55635, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 41s 221ms/step - loss: 3.6081 - accuracy: 0.1747 - f1_score: 0.1493 - val_loss: 3.5564 - val_accuracy: 0.1879 - val_f1_score: 0.1508\n",
      "Epoch 5/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.5146 - accuracy: 0.1891 - f1_score: 0.1634\n",
      "Epoch 5: val_loss improved from 3.55635 to 3.50311, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 41s 220ms/step - loss: 3.5151 - accuracy: 0.1890 - f1_score: 0.1633 - val_loss: 3.5031 - val_accuracy: 0.2028 - val_f1_score: 0.1654\n",
      "Epoch 6/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.4453 - accuracy: 0.2014 - f1_score: 0.1766\n",
      "Epoch 6: val_loss improved from 3.50311 to 3.44606, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 41s 220ms/step - loss: 3.4454 - accuracy: 0.2014 - f1_score: 0.1766 - val_loss: 3.4461 - val_accuracy: 0.1948 - val_f1_score: 0.1553\n",
      "Epoch 7/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.3907 - accuracy: 0.2021 - f1_score: 0.1789\n",
      "Epoch 7: val_loss improved from 3.44606 to 3.38344, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 41s 221ms/step - loss: 3.3911 - accuracy: 0.2021 - f1_score: 0.1790 - val_loss: 3.3834 - val_accuracy: 0.2125 - val_f1_score: 0.1781\n",
      "Epoch 8/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.3267 - accuracy: 0.2174 - f1_score: 0.1959\n",
      "Epoch 8: val_loss improved from 3.38344 to 3.38108, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 41s 220ms/step - loss: 3.3279 - accuracy: 0.2171 - f1_score: 0.1956 - val_loss: 3.3811 - val_accuracy: 0.2229 - val_f1_score: 0.1920\n",
      "Epoch 9/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.3107 - accuracy: 0.2207 - f1_score: 0.1995\n",
      "Epoch 9: val_loss improved from 3.38108 to 3.31880, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 41s 220ms/step - loss: 3.3105 - accuracy: 0.2208 - f1_score: 0.1995 - val_loss: 3.3188 - val_accuracy: 0.2258 - val_f1_score: 0.1901\n",
      "Epoch 10/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.2749 - accuracy: 0.2251 - f1_score: 0.2026\n",
      "Epoch 10: val_loss did not improve from 3.31880\n",
      "182/182 [==============================] - 40s 216ms/step - loss: 3.2741 - accuracy: 0.2253 - f1_score: 0.2028 - val_loss: 3.3371 - val_accuracy: 0.2225 - val_f1_score: 0.1826\n",
      "Epoch 11/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.2625 - accuracy: 0.2301 - f1_score: 0.2100\n",
      "Epoch 11: val_loss did not improve from 3.31880\n",
      "182/182 [==============================] - 40s 216ms/step - loss: 3.2628 - accuracy: 0.2302 - f1_score: 0.2100 - val_loss: 3.3228 - val_accuracy: 0.2346 - val_f1_score: 0.2045\n",
      "Epoch 12/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.2101 - accuracy: 0.2380 - f1_score: 0.2178\n",
      "Epoch 12: val_loss improved from 3.31880 to 3.27569, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 41s 220ms/step - loss: 3.2103 - accuracy: 0.2379 - f1_score: 0.2178 - val_loss: 3.2757 - val_accuracy: 0.2302 - val_f1_score: 0.1970\n",
      "Epoch 13/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.2096 - accuracy: 0.2339 - f1_score: 0.2138\n",
      "Epoch 13: val_loss did not improve from 3.27569\n",
      "182/182 [==============================] - 40s 216ms/step - loss: 3.2094 - accuracy: 0.2338 - f1_score: 0.2137 - val_loss: 3.3319 - val_accuracy: 0.2290 - val_f1_score: 0.1942\n",
      "Epoch 14/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.1918 - accuracy: 0.2358 - f1_score: 0.2155\n",
      "Epoch 14: val_loss improved from 3.27569 to 3.24236, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 41s 220ms/step - loss: 3.1921 - accuracy: 0.2358 - f1_score: 0.2154 - val_loss: 3.2424 - val_accuracy: 0.2471 - val_f1_score: 0.2188\n",
      "Epoch 15/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.1541 - accuracy: 0.2446 - f1_score: 0.2268\n",
      "Epoch 15: val_loss did not improve from 3.24236\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 3.1542 - accuracy: 0.2445 - f1_score: 0.2267 - val_loss: 3.2834 - val_accuracy: 0.2366 - val_f1_score: 0.2064\n",
      "Epoch 16/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.1729 - accuracy: 0.2397 - f1_score: 0.2212\n",
      "Epoch 16: val_loss did not improve from 3.24236\n",
      "182/182 [==============================] - 40s 216ms/step - loss: 3.1731 - accuracy: 0.2397 - f1_score: 0.2212 - val_loss: 3.2890 - val_accuracy: 0.2346 - val_f1_score: 0.2154\n",
      "Epoch 17/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.1461 - accuracy: 0.2418 - f1_score: 0.2232\n",
      "Epoch 17: val_loss did not improve from 3.24236\n",
      "182/182 [==============================] - 40s 216ms/step - loss: 3.1458 - accuracy: 0.2418 - f1_score: 0.2232 - val_loss: 3.2611 - val_accuracy: 0.2431 - val_f1_score: 0.2146\n",
      "Epoch 18/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.1109 - accuracy: 0.2506 - f1_score: 0.2342\n",
      "Epoch 18: val_loss improved from 3.24236 to 3.21274, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 41s 220ms/step - loss: 3.1107 - accuracy: 0.2505 - f1_score: 0.2341 - val_loss: 3.2127 - val_accuracy: 0.2543 - val_f1_score: 0.2207\n",
      "Epoch 19/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.1075 - accuracy: 0.2537 - f1_score: 0.2358\n",
      "Epoch 19: val_loss improved from 3.21274 to 3.18485, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 41s 220ms/step - loss: 3.1076 - accuracy: 0.2535 - f1_score: 0.2356 - val_loss: 3.1848 - val_accuracy: 0.2575 - val_f1_score: 0.2304\n",
      "Epoch 20/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.0972 - accuracy: 0.2551 - f1_score: 0.2366\n",
      "Epoch 20: val_loss did not improve from 3.18485\n",
      "182/182 [==============================] - 40s 216ms/step - loss: 3.0964 - accuracy: 0.2554 - f1_score: 0.2369 - val_loss: 3.2076 - val_accuracy: 0.2527 - val_f1_score: 0.2223\n",
      "Epoch 21/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.0656 - accuracy: 0.2594 - f1_score: 0.2419\n",
      "Epoch 21: val_loss improved from 3.18485 to 3.17277, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 41s 221ms/step - loss: 3.0660 - accuracy: 0.2594 - f1_score: 0.2419 - val_loss: 3.1728 - val_accuracy: 0.2656 - val_f1_score: 0.2378\n",
      "Epoch 22/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.0619 - accuracy: 0.2648 - f1_score: 0.2465\n",
      "Epoch 22: val_loss did not improve from 3.17277\n",
      "182/182 [==============================] - 40s 216ms/step - loss: 3.0622 - accuracy: 0.2647 - f1_score: 0.2466 - val_loss: 3.1895 - val_accuracy: 0.2640 - val_f1_score: 0.2391\n",
      "Epoch 23/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.0591 - accuracy: 0.2534 - f1_score: 0.2376\n",
      "Epoch 23: val_loss did not improve from 3.17277\n",
      "182/182 [==============================] - 40s 216ms/step - loss: 3.0593 - accuracy: 0.2534 - f1_score: 0.2376 - val_loss: 3.1843 - val_accuracy: 0.2648 - val_f1_score: 0.2389\n",
      "Epoch 24/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.0522 - accuracy: 0.2612 - f1_score: 0.2451\n",
      "Epoch 24: val_loss did not improve from 3.17277\n",
      "182/182 [==============================] - 40s 216ms/step - loss: 3.0525 - accuracy: 0.2611 - f1_score: 0.2450 - val_loss: 3.1842 - val_accuracy: 0.2567 - val_f1_score: 0.2302\n",
      "Epoch 25/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.0044 - accuracy: 0.2662 - f1_score: 0.2486\n",
      "Epoch 25: val_loss did not improve from 3.17277\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 3.0050 - accuracy: 0.2661 - f1_score: 0.2485 - val_loss: 3.1965 - val_accuracy: 0.2575 - val_f1_score: 0.2269\n",
      "Epoch 26/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.0093 - accuracy: 0.2737 - f1_score: 0.2571\n",
      "Epoch 26: val_loss did not improve from 3.17277\n",
      "182/182 [==============================] - 40s 216ms/step - loss: 3.0089 - accuracy: 0.2738 - f1_score: 0.2571 - val_loss: 3.1842 - val_accuracy: 0.2588 - val_f1_score: 0.2380\n",
      "Epoch 27/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.0157 - accuracy: 0.2682 - f1_score: 0.2522\n",
      "Epoch 27: val_loss improved from 3.17277 to 3.14548, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 41s 221ms/step - loss: 3.0155 - accuracy: 0.2682 - f1_score: 0.2521 - val_loss: 3.1455 - val_accuracy: 0.2676 - val_f1_score: 0.2443\n",
      "Epoch 28/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 3.0037 - accuracy: 0.2733 - f1_score: 0.2561\n",
      "Epoch 28: val_loss did not improve from 3.14548\n",
      "182/182 [==============================] - 40s 216ms/step - loss: 3.0037 - accuracy: 0.2734 - f1_score: 0.2561 - val_loss: 3.1556 - val_accuracy: 0.2716 - val_f1_score: 0.2516\n",
      "Epoch 29/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.9867 - accuracy: 0.2752 - f1_score: 0.2585\n",
      "Epoch 29: val_loss did not improve from 3.14548\n",
      "182/182 [==============================] - 40s 216ms/step - loss: 2.9879 - accuracy: 0.2750 - f1_score: 0.2582 - val_loss: 3.1499 - val_accuracy: 0.2596 - val_f1_score: 0.2364\n",
      "Epoch 30/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.9886 - accuracy: 0.2782 - f1_score: 0.2617\n",
      "Epoch 30: val_loss did not improve from 3.14548\n",
      "182/182 [==============================] - 40s 215ms/step - loss: 2.9884 - accuracy: 0.2783 - f1_score: 0.2618 - val_loss: 3.1679 - val_accuracy: 0.2696 - val_f1_score: 0.2397\n",
      "Epoch 31/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.9934 - accuracy: 0.2730 - f1_score: 0.2567\n",
      "Epoch 31: val_loss did not improve from 3.14548\n",
      "182/182 [==============================] - 40s 216ms/step - loss: 2.9936 - accuracy: 0.2731 - f1_score: 0.2568 - val_loss: 3.1590 - val_accuracy: 0.2596 - val_f1_score: 0.2358\n",
      "Epoch 32/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.9767 - accuracy: 0.2743 - f1_score: 0.2583\n",
      "Epoch 32: val_loss did not improve from 3.14548\n",
      "182/182 [==============================] - 40s 216ms/step - loss: 2.9767 - accuracy: 0.2744 - f1_score: 0.2583 - val_loss: 3.1512 - val_accuracy: 0.2704 - val_f1_score: 0.2399\n",
      "Epoch 33/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.9682 - accuracy: 0.2728 - f1_score: 0.2581\n",
      "Epoch 33: val_loss improved from 3.14548 to 3.13205, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 41s 221ms/step - loss: 2.9679 - accuracy: 0.2726 - f1_score: 0.2579 - val_loss: 3.1321 - val_accuracy: 0.2704 - val_f1_score: 0.2432\n",
      "Epoch 34/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.9601 - accuracy: 0.2797 - f1_score: 0.2643\n",
      "Epoch 34: val_loss did not improve from 3.13205\n",
      "182/182 [==============================] - 40s 216ms/step - loss: 2.9603 - accuracy: 0.2797 - f1_score: 0.2642 - val_loss: 3.1483 - val_accuracy: 0.2588 - val_f1_score: 0.2366\n",
      "Epoch 35/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.9489 - accuracy: 0.2783 - f1_score: 0.2637\n",
      "Epoch 35: val_loss did not improve from 3.13205\n",
      "182/182 [==============================] - 40s 216ms/step - loss: 2.9485 - accuracy: 0.2784 - f1_score: 0.2637 - val_loss: 3.1396 - val_accuracy: 0.2628 - val_f1_score: 0.2338\n",
      "Epoch 36/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.9302 - accuracy: 0.2811 - f1_score: 0.2671\n",
      "Epoch 36: val_loss improved from 3.13205 to 3.13112, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 41s 220ms/step - loss: 2.9301 - accuracy: 0.2809 - f1_score: 0.2669 - val_loss: 3.1311 - val_accuracy: 0.2620 - val_f1_score: 0.2350\n",
      "Epoch 37/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.9317 - accuracy: 0.2837 - f1_score: 0.2694\n",
      "Epoch 37: val_loss improved from 3.13112 to 3.10050, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 41s 221ms/step - loss: 2.9314 - accuracy: 0.2836 - f1_score: 0.2694 - val_loss: 3.1005 - val_accuracy: 0.2732 - val_f1_score: 0.2542\n",
      "Epoch 38/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.9157 - accuracy: 0.2865 - f1_score: 0.2716\n",
      "Epoch 38: val_loss did not improve from 3.10050\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 2.9155 - accuracy: 0.2865 - f1_score: 0.2715 - val_loss: 3.1586 - val_accuracy: 0.2640 - val_f1_score: 0.2448\n",
      "Epoch 39/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.9218 - accuracy: 0.2842 - f1_score: 0.2689\n",
      "Epoch 39: val_loss did not improve from 3.10050\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 2.9215 - accuracy: 0.2843 - f1_score: 0.2690 - val_loss: 3.1172 - val_accuracy: 0.2616 - val_f1_score: 0.2435\n",
      "Epoch 40/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.9365 - accuracy: 0.2820 - f1_score: 0.2673\n",
      "Epoch 40: val_loss did not improve from 3.10050\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 2.9366 - accuracy: 0.2819 - f1_score: 0.2671 - val_loss: 3.1116 - val_accuracy: 0.2708 - val_f1_score: 0.2492\n",
      "Epoch 41/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.9083 - accuracy: 0.2898 - f1_score: 0.2757\n",
      "Epoch 41: val_loss did not improve from 3.10050\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 2.9081 - accuracy: 0.2899 - f1_score: 0.2758 - val_loss: 3.1208 - val_accuracy: 0.2712 - val_f1_score: 0.2476\n",
      "Epoch 42/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.9017 - accuracy: 0.2926 - f1_score: 0.2777\n",
      "Epoch 42: val_loss did not improve from 3.10050\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 2.9012 - accuracy: 0.2928 - f1_score: 0.2778 - val_loss: 3.1126 - val_accuracy: 0.2692 - val_f1_score: 0.2477\n",
      "Epoch 43/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.9123 - accuracy: 0.2898 - f1_score: 0.2747\n",
      "Epoch 43: val_loss improved from 3.10050 to 3.09076, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 41s 222ms/step - loss: 2.9118 - accuracy: 0.2898 - f1_score: 0.2747 - val_loss: 3.0908 - val_accuracy: 0.2700 - val_f1_score: 0.2439\n",
      "Epoch 44/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.8871 - accuracy: 0.2882 - f1_score: 0.2745\n",
      "Epoch 44: val_loss did not improve from 3.09076\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 2.8874 - accuracy: 0.2880 - f1_score: 0.2744 - val_loss: 3.0939 - val_accuracy: 0.2789 - val_f1_score: 0.2571\n",
      "Epoch 45/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.8962 - accuracy: 0.2898 - f1_score: 0.2757\n",
      "Epoch 45: val_loss did not improve from 3.09076\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 2.8978 - accuracy: 0.2895 - f1_score: 0.2754 - val_loss: 3.1057 - val_accuracy: 0.2757 - val_f1_score: 0.2527\n",
      "Epoch 46/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.8896 - accuracy: 0.2907 - f1_score: 0.2758\n",
      "Epoch 46: val_loss improved from 3.09076 to 3.08221, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 41s 222ms/step - loss: 2.8892 - accuracy: 0.2908 - f1_score: 0.2759 - val_loss: 3.0822 - val_accuracy: 0.2801 - val_f1_score: 0.2577\n",
      "Epoch 47/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.8868 - accuracy: 0.2926 - f1_score: 0.2790\n",
      "Epoch 47: val_loss did not improve from 3.08221\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 2.8875 - accuracy: 0.2923 - f1_score: 0.2788 - val_loss: 3.1179 - val_accuracy: 0.2793 - val_f1_score: 0.2535\n",
      "Epoch 48/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.8765 - accuracy: 0.2986 - f1_score: 0.2858\n",
      "Epoch 48: val_loss did not improve from 3.08221\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 2.8764 - accuracy: 0.2987 - f1_score: 0.2860 - val_loss: 3.2337 - val_accuracy: 0.2567 - val_f1_score: 0.2328\n",
      "Epoch 49/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.8897 - accuracy: 0.2926 - f1_score: 0.2779\n",
      "Epoch 49: val_loss did not improve from 3.08221\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 2.8904 - accuracy: 0.2923 - f1_score: 0.2776 - val_loss: 3.1218 - val_accuracy: 0.2728 - val_f1_score: 0.2444\n",
      "Epoch 50/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.8886 - accuracy: 0.2865 - f1_score: 0.2736\n",
      "Epoch 50: val_loss did not improve from 3.08221\n",
      "182/182 [==============================] - 40s 218ms/step - loss: 2.8878 - accuracy: 0.2867 - f1_score: 0.2739 - val_loss: 3.1282 - val_accuracy: 0.2736 - val_f1_score: 0.2527\n",
      "Epoch 51/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.8715 - accuracy: 0.2985 - f1_score: 0.2851\n",
      "Epoch 51: val_loss did not improve from 3.08221\n",
      "182/182 [==============================] - 40s 218ms/step - loss: 2.8727 - accuracy: 0.2983 - f1_score: 0.2849 - val_loss: 3.1013 - val_accuracy: 0.2736 - val_f1_score: 0.2473\n",
      "Epoch 52/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.8851 - accuracy: 0.2900 - f1_score: 0.2766\n",
      "Epoch 52: val_loss improved from 3.08221 to 3.07197, saving model to inceptionv3_model_best.weights.hdf5\n",
      "182/182 [==============================] - 41s 221ms/step - loss: 2.8853 - accuracy: 0.2898 - f1_score: 0.2765 - val_loss: 3.0720 - val_accuracy: 0.2797 - val_f1_score: 0.2598\n",
      "Epoch 53/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.8648 - accuracy: 0.2977 - f1_score: 0.2837\n",
      "Epoch 53: val_loss did not improve from 3.07197\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 2.8651 - accuracy: 0.2977 - f1_score: 0.2837 - val_loss: 3.0787 - val_accuracy: 0.2805 - val_f1_score: 0.2566\n",
      "Epoch 54/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.8641 - accuracy: 0.2938 - f1_score: 0.2798\n",
      "Epoch 54: val_loss did not improve from 3.07197\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 2.8643 - accuracy: 0.2937 - f1_score: 0.2797 - val_loss: 3.0867 - val_accuracy: 0.2821 - val_f1_score: 0.2635\n",
      "Epoch 55/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.8446 - accuracy: 0.3033 - f1_score: 0.2898\n",
      "Epoch 55: val_loss did not improve from 3.07197\n",
      "182/182 [==============================] - 40s 218ms/step - loss: 2.8444 - accuracy: 0.3032 - f1_score: 0.2898 - val_loss: 3.1094 - val_accuracy: 0.2728 - val_f1_score: 0.2488\n",
      "Epoch 56/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.8615 - accuracy: 0.2912 - f1_score: 0.2775\n",
      "Epoch 56: val_loss did not improve from 3.07197\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 2.8620 - accuracy: 0.2911 - f1_score: 0.2774 - val_loss: 3.0875 - val_accuracy: 0.2712 - val_f1_score: 0.2513\n",
      "Epoch 57/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.8375 - accuracy: 0.2975 - f1_score: 0.2855\n",
      "Epoch 57: val_loss did not improve from 3.07197\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 2.8375 - accuracy: 0.2974 - f1_score: 0.2855 - val_loss: 3.1097 - val_accuracy: 0.2700 - val_f1_score: 0.2458\n",
      "Epoch 58/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.8338 - accuracy: 0.3061 - f1_score: 0.2935\n",
      "Epoch 58: val_loss did not improve from 3.07197\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 2.8340 - accuracy: 0.3060 - f1_score: 0.2934 - val_loss: 3.0841 - val_accuracy: 0.2712 - val_f1_score: 0.2519\n",
      "Epoch 59/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.8428 - accuracy: 0.2951 - f1_score: 0.2823\n",
      "Epoch 59: val_loss did not improve from 3.07197\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 2.8432 - accuracy: 0.2951 - f1_score: 0.2824 - val_loss: 3.0858 - val_accuracy: 0.2793 - val_f1_score: 0.2591\n",
      "Epoch 60/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.8440 - accuracy: 0.2977 - f1_score: 0.2843\n",
      "Epoch 60: val_loss did not improve from 3.07197\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 2.8451 - accuracy: 0.2973 - f1_score: 0.2839 - val_loss: 3.1275 - val_accuracy: 0.2688 - val_f1_score: 0.2463\n",
      "Epoch 61/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.8256 - accuracy: 0.2969 - f1_score: 0.2841\n",
      "Epoch 61: val_loss did not improve from 3.07197\n",
      "182/182 [==============================] - 40s 217ms/step - loss: 2.8260 - accuracy: 0.2967 - f1_score: 0.2840 - val_loss: 3.0866 - val_accuracy: 0.2793 - val_f1_score: 0.2592\n",
      "Epoch 62/200\n",
      "181/182 [============================>.] - ETA: 0s - loss: 2.8397 - accuracy: 0.3015 - f1_score: 0.2887\n",
      "Epoch 62: val_loss did not improve from 3.07197\n",
      "182/182 [==============================] - 40s 219ms/step - loss: 2.8397 - accuracy: 0.3016 - f1_score: 0.2888 - val_loss: 3.0904 - val_accuracy: 0.2757 - val_f1_score: 0.2571\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=200,\n",
    "                    validation_data=val_generator,\n",
    "                    callbacks=[checkpoint, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "K4uieaPax7RY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K4uieaPax7RY",
    "outputId": "3e2950f4-ab9a-4cb2-ffbd-5a461ebb0e39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 12s 296ms/step - loss: 3.0604 - accuracy: 0.2844 - f1_score: 0.2574\n",
      "Test Loss: 3.0604236125946045\n",
      "Test Accuracy: 0.2843925952911377\n",
      "Test F1 Score: 0.257374107837677\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "model.load_weights('inceptionv3_model_best.weights.hdf5')\n",
    "loss, accuracy, f1 = model.evaluate(test_generator)\n",
    "\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Test F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "Fq5AuKek1joi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "Fq5AuKek1joi",
    "outputId": "7f27c08e-b7ae-42fe-e26a-3b81f21f2949"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss visualization\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Jkk_4Kuf7z5-",
   "metadata": {
    "id": "Jkk_4Kuf7z5-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
