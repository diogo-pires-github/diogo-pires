{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0061c94-488f-4ee2-a883-2fb728a83626",
   "metadata": {},
   "source": [
    "# Image Classification - Pap smear images for Cervical Cancer screening\n",
    "**A simple implementation of a image classifier using Keras**\n",
    "\n",
    "Data source: SipakMed https://www.kaggle.com/datasets/prahladmehandiratta/cervical-cancer-largest-dataset-sipakmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3876b50e-61df-49fe-9c18-4bf56624aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Tensorflow/Keras imports\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee50d7a-b228-4f97-93fa-0e03dde51c5b",
   "metadata": {},
   "source": [
    "Note: when replicating this code, it's possible to have some versioning issues with the imports. The reason behind is that I want to use the GPU/CUDA and TensorFlow 2.10 was the last TensorFlow release that supported GPU on native-Windows.\n",
    "For more information check: https://www.tensorflow.org/install/pip#windows-native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e91d567-2c5d-46de-8864-fa1ec184a766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Checing if GPU is available\n",
    "print(\"Num GPUs Available: \", len(tensorflow.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4114ea58-6e62-4d77-90a8-a72c5ae4d385",
   "metadata": {},
   "source": [
    "## 1 - Extract the images stored in 'archive' zip file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4982d8ed-d41a-40da-b370-3d904b5ecbee",
   "metadata": {},
   "source": [
    "For simplicty I already extracted the data from Kaggle to a local archive.zip file.\n",
    "\n",
    "You can do the same by following this guide: https://www.geeksforgeeks.org/how-to-download-kaggle-datasets-into-jupyter-notebook/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "967449e8-8095-4e01-8832-3c171f0c95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's extract our images in archive.zip\n",
    "def extract_cropped_images(zip_path, extraction_path):\n",
    "    # Open the zip file\n",
    "    with zipfile.ZipFile(zip_path, 'r') as archive:\n",
    "        # Iterate through each file\n",
    "        for file_info in archive.infolist():\n",
    "            # Check if the file is a .bmp file within a CROPPED subfolder\n",
    "            if file_info.filename.endswith('.bmp') and 'CROPPED' in file_info.filename:\n",
    "                # Split the path to get the necessary components\n",
    "                parts = file_info.filename.split('/')\n",
    "                # Extract the first subfolder name as the label\n",
    "                label = parts[1]\n",
    "                # Get the image filename\n",
    "                image_filename = parts[-1]\n",
    "                # Destination path\n",
    "                destination_dir = os.path.join(extraction_path, label)\n",
    "                destination_path = os.path.join(destination_dir, image_filename)\n",
    "                # Create the directory (if it doesn't exist)\n",
    "                os.makedirs(destination_dir, exist_ok=True)\n",
    "                # Extract the images\n",
    "                with archive.open(file_info) as source_file:\n",
    "                    with open(destination_path, 'wb') as dest_file:\n",
    "                        shutil.copyfileobj(source_file, dest_file)\n",
    "    print(f\"Images extracted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e76707-575e-48f2-ac2e-57f7e536d9f2",
   "metadata": {},
   "source": [
    "TLDR: we just want to grab the images.bmp from the CROPPED file inside the archive.zip file. And we want to keep these images inside their respective subfolders - these subfolders represent the target labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "427d82d5-0d94-49a5-a672-2cfa510f7727",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = 'archive.zip'\n",
    "extraction_path = 'cropped_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e75e2c-07ff-4451-b067-c6c61e999079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images extracted!\n"
     ]
    }
   ],
   "source": [
    "extract_cropped_images(zip_path, extraction_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6baf946-b96d-4a41-9c32-fa7b5dd9438a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "813 images in 'im_Dyskeratotic'.\n",
      "825 images in 'im_Koilocytotic'.\n",
      "793 images in 'im_Metaplastic'.\n",
      "787 images in 'im_Parabasal'.\n",
      "831 images in 'im_Superficial-Intermediate'.\n"
     ]
    }
   ],
   "source": [
    "# Checking the number of images of each label\n",
    "for subfolder in os.listdir(extraction_path):\n",
    "        subfolder_path = os.path.join(extraction_path, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            # Count the number of .bmp files in the subfolder\n",
    "            num_images = len([name for name in os.listdir(subfolder_path) if name.endswith('.bmp')])\n",
    "            print(f\"{num_images} images in '{subfolder}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e50db8f-a4d7-4280-9c40-d878f8c9d0fd",
   "metadata": {},
   "source": [
    "## 2 - Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c17d69f-0ec5-4bb4-80bc-ee8c0c83cd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3241 images belonging to 5 classes.\n",
      "Found 808 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 224, 224\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    extraction_path,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    extraction_path,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d25c4e-13e6-4763-ac36-76b4f992db57",
   "metadata": {},
   "source": [
    "## 3 - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fa4f512-0210-4e81-ad89-40f54888aba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 111, 111, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 55, 55, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 55, 55, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 27, 27, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 27, 27, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 13, 13, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,285\n",
      "Trainable params: 521,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building a simple CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    GlobalAveragePooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(rate=0.2),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(rate=0.2),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b72d48e8-4316-448a-a6a2-1b460f3b039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "opt_adam = Adam(learning_rate=0.001)\n",
    "f1 = F1Score(num_classes=5, average='weighted')\n",
    "\n",
    "model.compile(optimizer=opt_adam, loss='categorical_crossentropy', metrics=['accuracy',f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3359305-54ec-4609-a955-c400d2647661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint callback - save best weights\n",
    "chekpoint = ModelCheckpoint(filepath='best_weights.hdf5', save_best_only=True, verbose=1)\n",
    "\n",
    "# EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a832033f-64b8-405c-81ff-a0d27d4c4dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "102/102 [==============================] - ETA: 0s - loss: 1.2535 - accuracy: 0.4249 - f1_score: 0.4095\n",
      "Epoch 1: val_loss improved from inf to 1.35906, saving model to best_weights.hdf5\n",
      "102/102 [==============================] - 31s 210ms/step - loss: 1.2535 - accuracy: 0.4249 - f1_score: 0.4095 - val_loss: 1.3591 - val_accuracy: 0.4715 - val_f1_score: 0.4236\n",
      "Epoch 2/20\n",
      "101/102 [============================>.] - ETA: 0s - loss: 1.0068 - accuracy: 0.5834 - f1_score: 0.5766\n",
      "Epoch 2: val_loss improved from 1.35906 to 1.04118, saving model to best_weights.hdf5\n",
      "102/102 [==============================] - 5s 51ms/step - loss: 1.0077 - accuracy: 0.5838 - f1_score: 0.5769 - val_loss: 1.0412 - val_accuracy: 0.6460 - val_f1_score: 0.6002\n",
      "Epoch 3/20\n",
      "101/102 [============================>.] - ETA: 0s - loss: 0.8469 - accuracy: 0.6874 - f1_score: 0.6848\n",
      "Epoch 3: val_loss improved from 1.04118 to 0.96544, saving model to best_weights.hdf5\n",
      "102/102 [==============================] - 5s 52ms/step - loss: 0.8455 - accuracy: 0.6884 - f1_score: 0.6858 - val_loss: 0.9654 - val_accuracy: 0.6262 - val_f1_score: 0.6071\n",
      "Epoch 4/20\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.7407 - accuracy: 0.7322 - f1_score: 0.7315\n",
      "Epoch 4: val_loss did not improve from 0.96544\n",
      "102/102 [==============================] - 5s 50ms/step - loss: 0.7407 - accuracy: 0.7322 - f1_score: 0.7315 - val_loss: 1.0582 - val_accuracy: 0.6139 - val_f1_score: 0.5707\n",
      "Epoch 5/20\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.6794 - accuracy: 0.7587 - f1_score: 0.7583\n",
      "Epoch 5: val_loss did not improve from 0.96544\n",
      "102/102 [==============================] - 5s 51ms/step - loss: 0.6794 - accuracy: 0.7587 - f1_score: 0.7583 - val_loss: 1.2232 - val_accuracy: 0.6188 - val_f1_score: 0.5806\n",
      "Epoch 6/20\n",
      "101/102 [============================>.] - ETA: 0s - loss: 0.6482 - accuracy: 0.7691 - f1_score: 0.7688\n",
      "Epoch 6: val_loss did not improve from 0.96544\n",
      "102/102 [==============================] - 5s 53ms/step - loss: 0.6449 - accuracy: 0.7698 - f1_score: 0.7696 - val_loss: 1.3909 - val_accuracy: 0.6064 - val_f1_score: 0.5477\n",
      "Epoch 7/20\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.5953 - accuracy: 0.7877 - f1_score: 0.7874\n",
      "Epoch 7: val_loss did not improve from 0.96544\n",
      "102/102 [==============================] - 5s 51ms/step - loss: 0.5953 - accuracy: 0.7877 - f1_score: 0.7874 - val_loss: 1.4402 - val_accuracy: 0.6287 - val_f1_score: 0.5580\n",
      "Epoch 8/20\n",
      "101/102 [============================>.] - ETA: 0s - loss: 0.5546 - accuracy: 0.8002 - f1_score: 0.7998\n",
      "Epoch 8: val_loss did not improve from 0.96544\n",
      "102/102 [==============================] - 5s 53ms/step - loss: 0.5545 - accuracy: 0.8001 - f1_score: 0.7996 - val_loss: 1.5979 - val_accuracy: 0.6262 - val_f1_score: 0.5700\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=20,\n",
    "                    validation_data=validation_generator,\n",
    "                    callbacks=[chekpoint, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27d64a7c-4bf8-49e7-be37-dbc805ff8286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 30ms/step - loss: 0.9654 - accuracy: 0.6262 - f1_score: 0.6071\n",
      "Val Loss: 0.9654361009597778\n",
      "Val Accuracy: 0.6262376308441162\n",
      "Val F1 Score: 0.6071136593818665\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.load_weights('best_weights.hdf5')\n",
    "loss, accuracy, f1 = model.evaluate(validation_generator)\n",
    "\n",
    "print(\"Val Loss:\", loss)\n",
    "print(\"Val Accuracy:\", accuracy)\n",
    "print(\"Val F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05a5c332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 29ms/step\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            im_Dyskeratotic       0.86      0.73      0.79       162\n",
      "            im_Koilocytotic       0.43      0.35      0.38       165\n",
      "             im_Metaplastic       0.86      0.83      0.84       158\n",
      "               im_Parabasal       0.56      0.99      0.71       157\n",
      "im_Superficial-Intermediate       0.42      0.27      0.33       166\n",
      "\n",
      "                   accuracy                           0.63       808\n",
      "                  macro avg       0.62      0.63      0.61       808\n",
      "               weighted avg       0.62      0.63      0.61       808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the predictions\n",
    "preds = model.predict(validation_generator)\n",
    "predicted_classes = tensorflow.argmax(preds, axis=1)\n",
    "# Get the true classes\n",
    "true_classes = validation_generator.classes\n",
    "# Get the classification report\n",
    "print(classification_report(true_classes, predicted_classes, target_names=validation_generator.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284f9586-597e-4298-8da8-9e779f0b2b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
